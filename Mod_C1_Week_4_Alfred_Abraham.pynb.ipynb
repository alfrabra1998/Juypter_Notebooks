{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f80ba51a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>length_url</th>\n",
       "      <th>length_hostname</th>\n",
       "      <th>ip</th>\n",
       "      <th>nb_dots</th>\n",
       "      <th>nb_hyphens</th>\n",
       "      <th>nb_at</th>\n",
       "      <th>nb_qm</th>\n",
       "      <th>nb_and</th>\n",
       "      <th>nb_or</th>\n",
       "      <th>...</th>\n",
       "      <th>domain_in_title</th>\n",
       "      <th>domain_with_copyright</th>\n",
       "      <th>whois_registered_domain</th>\n",
       "      <th>domain_registration_length</th>\n",
       "      <th>domain_age</th>\n",
       "      <th>web_traffic</th>\n",
       "      <th>dns_record</th>\n",
       "      <th>google_index</th>\n",
       "      <th>page_rank</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.crestonwood.com/router.php</td>\n",
       "      <td>37</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>legitimate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://shadetreetechnology.com/V4/validation/a...</td>\n",
       "      <td>77</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>5767</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://support-appleld.com.secureupdate.duila...</td>\n",
       "      <td>126</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>4004</td>\n",
       "      <td>5828815</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://rgipt.ac.in</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>-1</td>\n",
       "      <td>107721</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>legitimate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.iracing.com/tracks/gateway-motorspo...</td>\n",
       "      <td>55</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>224</td>\n",
       "      <td>8175</td>\n",
       "      <td>8725</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>legitimate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11425</th>\n",
       "      <td>http://www.fontspace.com/category/blackletter</td>\n",
       "      <td>45</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>448</td>\n",
       "      <td>5396</td>\n",
       "      <td>3980</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>legitimate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11426</th>\n",
       "      <td>http://www.budgetbots.com/server.php/Server%20...</td>\n",
       "      <td>84</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211</td>\n",
       "      <td>6728</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11427</th>\n",
       "      <td>https://www.facebook.com/Interactive-Televisio...</td>\n",
       "      <td>105</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2809</td>\n",
       "      <td>8515</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>legitimate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11428</th>\n",
       "      <td>http://www.mypublicdomainpictures.com/</td>\n",
       "      <td>38</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>2836</td>\n",
       "      <td>2455493</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>legitimate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11429</th>\n",
       "      <td>http://174.139.46.123/ap/signin?openid.pape.ma...</td>\n",
       "      <td>477</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11430 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     url  length_url  \\\n",
       "0                  http://www.crestonwood.com/router.php          37   \n",
       "1      http://shadetreetechnology.com/V4/validation/a...          77   \n",
       "2      https://support-appleld.com.secureupdate.duila...         126   \n",
       "3                                     http://rgipt.ac.in          18   \n",
       "4      http://www.iracing.com/tracks/gateway-motorspo...          55   \n",
       "...                                                  ...         ...   \n",
       "11425      http://www.fontspace.com/category/blackletter          45   \n",
       "11426  http://www.budgetbots.com/server.php/Server%20...          84   \n",
       "11427  https://www.facebook.com/Interactive-Televisio...         105   \n",
       "11428             http://www.mypublicdomainpictures.com/          38   \n",
       "11429  http://174.139.46.123/ap/signin?openid.pape.ma...         477   \n",
       "\n",
       "       length_hostname  ip  nb_dots  nb_hyphens  nb_at  nb_qm  nb_and  nb_or  \\\n",
       "0                   19   0        3           0      0      0       0      0   \n",
       "1                   23   1        1           0      0      0       0      0   \n",
       "2                   50   1        4           1      0      1       2      0   \n",
       "3                   11   0        2           0      0      0       0      0   \n",
       "4                   15   0        2           2      0      0       0      0   \n",
       "...                ...  ..      ...         ...    ...    ...     ...    ...   \n",
       "11425               17   0        2           0      0      0       0      0   \n",
       "11426               18   0        5           0      1      1       0      0   \n",
       "11427               16   1        2           6      0      1       0      0   \n",
       "11428               30   0        2           0      0      0       0      0   \n",
       "11429               14   1       24           0      1      1       9      0   \n",
       "\n",
       "       ...  domain_in_title  domain_with_copyright  whois_registered_domain  \\\n",
       "0      ...                0                      1                        0   \n",
       "1      ...                1                      0                        0   \n",
       "2      ...                1                      0                        0   \n",
       "3      ...                1                      0                        0   \n",
       "4      ...                0                      1                        0   \n",
       "...    ...              ...                    ...                      ...   \n",
       "11425  ...                0                      0                        0   \n",
       "11426  ...                1                      0                        0   \n",
       "11427  ...                0                      0                        0   \n",
       "11428  ...                1                      0                        0   \n",
       "11429  ...                1                      1                        1   \n",
       "\n",
       "       domain_registration_length  domain_age  web_traffic  dns_record  \\\n",
       "0                              45          -1            0           1   \n",
       "1                              77        5767            0           0   \n",
       "2                              14        4004      5828815           0   \n",
       "3                              62          -1       107721           0   \n",
       "4                             224        8175         8725           0   \n",
       "...                           ...         ...          ...         ...   \n",
       "11425                         448        5396         3980           0   \n",
       "11426                         211        6728            0           0   \n",
       "11427                        2809        8515            8           0   \n",
       "11428                          85        2836      2455493           0   \n",
       "11429                           0          -1            0           1   \n",
       "\n",
       "       google_index  page_rank      status  \n",
       "0                 1          4  legitimate  \n",
       "1                 1          2    phishing  \n",
       "2                 1          0    phishing  \n",
       "3                 0          3  legitimate  \n",
       "4                 0          6  legitimate  \n",
       "...             ...        ...         ...  \n",
       "11425             0          6  legitimate  \n",
       "11426             1          0    phishing  \n",
       "11427             1         10  legitimate  \n",
       "11428             0          4  legitimate  \n",
       "11429             1          0    phishing  \n",
       "\n",
       "[11430 rows x 89 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Phishing_Data = pd.read_csv(\"C:\\\\Users\\\\alfre_g2qn6y7\\\\OneDrive\\\\Documents\\\\dataset_phishing.csv\")\n",
    "Phishing_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5884c6c",
   "metadata": {},
   "source": [
    "Do Logistic Regression pre-feature scaling to predict class (phishing or legitimate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "589e8994",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alfre_g2qn6y7\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7891513560804899"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = Phishing_Data.drop([\"url\",\"status\"],axis =1)\n",
    "y = Phishing_Data[\"status\"]\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "model_LR_pre_scaling = LogisticRegression()\n",
    "model_LR_pre_scaling.fit(X_train,y_train)\n",
    "y_pred = model_LR_pre_scaling.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b527e22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  legitimate       0.80      0.78      0.79      1157\n",
      "    phishing       0.78      0.80      0.79      1129\n",
      "\n",
      "    accuracy                           0.79      2286\n",
      "   macro avg       0.79      0.79      0.79      2286\n",
      "weighted avg       0.79      0.79      0.79      2286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test,y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2118d166",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alfre_g2qn6y7\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\alfre_g2qn6y7\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\alfre_g2qn6y7\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\alfre_g2qn6y7\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\alfre_g2qn6y7\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7829396325459317"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(model_LR_pre_scaling, X, y, cv=kf, scoring='accuracy')\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff9ce90",
   "metadata": {},
   "source": [
    "Based on this, the preicision and recall scores are roughly the same for both legitimate and phishing even though the accuracy, 79%, leaves something to be desired. Cross validation gives us a slightly lower accuracy (78%).  Now incorporate Standard Scaler. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f5e0e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9558180227471567"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "model_LR_scaled = LogisticRegression()\n",
    "model_LR_scaled.fit(X_train_scaled,y_train)\n",
    "y_pred = model_LR_scaled.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d79c9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  legitimate       0.95      0.96      0.96      1157\n",
      "    phishing       0.96      0.95      0.96      1129\n",
      "\n",
      "    accuracy                           0.96      2286\n",
      "   macro avg       0.96      0.96      0.96      2286\n",
      "weighted avg       0.96      0.96      0.96      2286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test,y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca56c528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9424763684523475"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(model_LR_scaled, X_train_scaled, y_train, cv=kf, scoring='accuracy')\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c42bf4",
   "metadata": {},
   "source": [
    "The accuracy is very high for the test set (approx. 96%) and for cross-validation (approx. 94%). There is no substantial difference between precision and recall scores for the legitimate and phishing categories. Now do Logistic Regression with normalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16ee5800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.894575678040245"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "X_test_norm = scaler.transform(X_test)\n",
    "model_LR_norm = LogisticRegression()\n",
    "model_LR_norm.fit(X_train_scaled,y_train)\n",
    "y_pred = model_LR_norm.predict(X_test_norm)\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08336335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  legitimate       0.97      0.82      0.89      1157\n",
      "    phishing       0.84      0.97      0.90      1129\n",
      "\n",
      "    accuracy                           0.89      2286\n",
      "   macro avg       0.90      0.90      0.89      2286\n",
      "weighted avg       0.90      0.89      0.89      2286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test,y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65d5fc9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9348211946358991"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(model_LR_norm, X_train_norm, y_train, cv=kf, scoring='accuracy')\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b7f8d4",
   "metadata": {},
   "source": [
    "The accuracy is still pretty good but less than for standardization (89% for test set, 93% for cross validation). It is interesting to note that the precision and recall scores are almost flipped; a sharp rise in one corresponds with a sharp fall in the other when both categories are compared. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab62d3ac-875c-43c8-bb93-8df621be00e6",
   "metadata": {},
   "source": [
    "Now let's do Grid Search with the standardized Logistic Regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcb36e50-d819-4c44-aa69-5e0e105e8580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best parameters: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best cross-validation score: 0.9426\n",
      "Test set accuracy with best model: 0.9576\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  legitimate       0.96      0.96      0.96      1157\n",
      "    phishing       0.96      0.95      0.96      1129\n",
      "\n",
      "    accuracy                           0.96      2286\n",
      "   macro avg       0.96      0.96      0.96      2286\n",
      "weighted avg       0.96      0.96      0.96      2286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "logistic_regression = LogisticRegression()\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10,100],  # Inverse of regularization strength\n",
    "    'penalty': ['l1', 'l2'],            # Regularization type (L1 or L2)\n",
    "    'solver': ['liblinear', 'saga']     # Solvers that support both L1 and L2\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=logistic_regression,\n",
    "                           param_grid=param_grid,\n",
    "                           cv=5,\n",
    "                           scoring='accuracy',\n",
    "                           verbose=1,\n",
    "                           n_jobs=-1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
    "best_model = grid_search.best_estimator_\n",
    "test_accuracy = best_model.score(X_test_scaled, y_test)\n",
    "print(f\"Test set accuracy with best model: {test_accuracy:.4f}\")\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "report = classification_report(y_test,y_pred)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc01ecab-2974-4c5d-9e45-e433746bc619",
   "metadata": {},
   "source": [
    "Based on this, the cross validation and test accuracy scores are somewhat better than that of the pre-Grid Search standardized model. The precision and recall scores for both legitimate and phishing websites are somewhat higher (they were already pretty high to begin with so you couldn't go much higher). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b37a67bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Email Text</th>\n",
       "      <th>Email Type</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_words</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>num_capitals</th>\n",
       "      <th>num_exclamations</th>\n",
       "      <th>num_question_marks</th>\n",
       "      <th>num_special_chars</th>\n",
       "      <th>num_digits</th>\n",
       "      <th>num_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>re : 6 . 1100 , disc : uniformitarianism , re ...</td>\n",
       "      <td>Safe Email</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>3.482609</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>the other side of * galicismos * * galicismo *...</td>\n",
       "      <td>Safe Email</td>\n",
       "      <td>479.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>4.274725</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>re : equistar deal tickets are you still avail...</td>\n",
       "      <td>Safe Email</td>\n",
       "      <td>1245.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>3.085246</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\\nHello I am your hot lil horny toy.\\n    I am...</td>\n",
       "      <td>Phishing Email</td>\n",
       "      <td>688.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>software at incredibly low prices ( 86 % lower...</td>\n",
       "      <td>Phishing Email</td>\n",
       "      <td>441.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17711</th>\n",
       "      <td>18646</td>\n",
       "      <td>date a lonely housewife always wanted to date ...</td>\n",
       "      <td>Phishing Email</td>\n",
       "      <td>237.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>4.288889</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17712</th>\n",
       "      <td>18647</td>\n",
       "      <td>request submitted : access request for anita ....</td>\n",
       "      <td>Safe Email</td>\n",
       "      <td>477.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>3.828283</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17713</th>\n",
       "      <td>18648</td>\n",
       "      <td>re : important - prc mtg hi dorn &amp; john , as y...</td>\n",
       "      <td>Safe Email</td>\n",
       "      <td>1214.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>3.802372</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17714</th>\n",
       "      <td>18649</td>\n",
       "      <td>press clippings - letter on californian utilit...</td>\n",
       "      <td>Safe Email</td>\n",
       "      <td>213.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5.294118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17715</th>\n",
       "      <td>18650</td>\n",
       "      <td>empty</td>\n",
       "      <td>Phishing Email</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17716 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                         Email Text  \\\n",
       "0               0  re : 6 . 1100 , disc : uniformitarianism , re ...   \n",
       "1               1  the other side of * galicismos * * galicismo *...   \n",
       "2               2  re : equistar deal tickets are you still avail...   \n",
       "3               3  \\nHello I am your hot lil horny toy.\\n    I am...   \n",
       "4               4  software at incredibly low prices ( 86 % lower...   \n",
       "...           ...                                                ...   \n",
       "17711       18646  date a lonely housewife always wanted to date ...   \n",
       "17712       18647  request submitted : access request for anita ....   \n",
       "17713       18648  re : important - prc mtg hi dorn & john , as y...   \n",
       "17714       18649  press clippings - letter on californian utilit...   \n",
       "17715       18650                                              empty   \n",
       "\n",
       "           Email Type  num_chars  num_words  avg_word_len  num_sentences  \\\n",
       "0          Safe Email     1030.0      230.0      3.482609            9.0   \n",
       "1          Safe Email      479.0       91.0      4.274725            6.0   \n",
       "2          Safe Email     1245.0      305.0      3.085246            7.0   \n",
       "3      Phishing Email      688.0       96.0      5.500000           38.0   \n",
       "4      Phishing Email      441.0       91.0      3.857143           13.0   \n",
       "...               ...        ...        ...           ...            ...   \n",
       "17711  Phishing Email      237.0       45.0      4.288889            6.0   \n",
       "17712      Safe Email      477.0       99.0      3.828283            8.0   \n",
       "17713      Safe Email     1214.0      253.0      3.802372           13.0   \n",
       "17714      Safe Email      213.0       34.0      5.294118            0.0   \n",
       "17715  Phishing Email        5.0        1.0      5.000000            0.0   \n",
       "\n",
       "       num_capitals  num_exclamations  num_question_marks  num_special_chars  \\\n",
       "0               0.0               2.0                 0.0               59.0   \n",
       "1               0.0               0.0                 2.0               16.0   \n",
       "2               0.0               0.0                 1.0               95.0   \n",
       "3              39.0               1.0                 1.0              110.0   \n",
       "4               0.0               0.0                 0.0               27.0   \n",
       "...             ...               ...                 ...                ...   \n",
       "17711           0.0               0.0                 1.0                8.0   \n",
       "17712           0.0               0.0                 0.0               31.0   \n",
       "17713           0.0               1.0                 1.0               38.0   \n",
       "17714           0.0               0.0                 0.0                8.0   \n",
       "17715           0.0               0.0                 0.0                0.0   \n",
       "\n",
       "       num_digits  num_urls  \n",
       "0             9.0       0.0  \n",
       "1             0.0       0.0  \n",
       "2            63.0       0.0  \n",
       "3            29.0       1.0  \n",
       "4             2.0       0.0  \n",
       "...           ...       ...  \n",
       "17711         0.0       0.0  \n",
       "17712        24.0       0.0  \n",
       "17713         0.0       0.0  \n",
       "17714         0.0       0.0  \n",
       "17715         0.0       0.0  \n",
       "\n",
       "[17716 rows x 13 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Email = pd.read_csv(\"C:\\\\Users\\\\alfre_g2qn6y7\\\\OneDrive\\\\Documents\\\\Phishing_Email.csv\")\n",
    "Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd97b2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alfre_g2qn6y7\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7389954853273137"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = Email.drop([\"Unnamed: 0\",\"Email Text\",\"Email Type\"],axis =1)\n",
    "y = Email[\"Email Type\"]\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "model_LR_pre_scaling = LogisticRegression()\n",
    "model_LR_pre_scaling.fit(X_train,y_train)\n",
    "y_pred = model_LR_pre_scaling.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2a1410b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "Phishing Email       0.81      0.46      0.59      1429\n",
      "    Safe Email       0.72      0.93      0.81      2115\n",
      "\n",
      "      accuracy                           0.74      3544\n",
      "     macro avg       0.76      0.69      0.70      3544\n",
      "  weighted avg       0.75      0.74      0.72      3544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test,y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f149a6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alfre_g2qn6y7\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alfre_g2qn6y7\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alfre_g2qn6y7\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alfre_g2qn6y7\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alfre_g2qn6y7\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7403485969536472"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(model_LR_pre_scaling, X,y, cv=kf, scoring='accuracy')\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920fa84a",
   "metadata": {},
   "source": [
    "The test and cross validation accuracy scores (approx. 74% for both) leave something to be desired. What is especially worrying however is that the recall score for phishing emails is less than 50%. Now let's see what happens when the class weight parameter is set to 'balanced'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5844cbe-47a1-4eaf-843a-2dfa4050c041",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alfre_g2qn6y7\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7494356659142212"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LR_pre_scaling = LogisticRegression(class_weight = 'balanced')\n",
    "model_LR_pre_scaling.fit(X_train,y_train)\n",
    "y_pred = model_LR_pre_scaling.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a69b0167-d901-4585-b6fe-68693305b930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "Phishing Email       0.67      0.73      0.70      1429\n",
      "    Safe Email       0.81      0.76      0.78      2115\n",
      "\n",
      "      accuracy                           0.75      3544\n",
      "     macro avg       0.74      0.75      0.74      3544\n",
      "  weighted avg       0.75      0.75      0.75      3544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test,y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78a4b273-ded9-4e0a-83cd-4a69571c2649",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alfre_g2qn6y7\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alfre_g2qn6y7\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alfre_g2qn6y7\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alfre_g2qn6y7\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alfre_g2qn6y7\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7296026207341192"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(model_LR_pre_scaling, X_train, y_train, cv=kf, scoring='accuracy')\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e9427b-40ea-4692-af7b-b3cc8b9da708",
   "metadata": {},
   "source": [
    "There is a slight improvment in testing accuracy after balancing but cross validation accuracy is lower. Also, while recall is much better for phishing emails, precision is significantly lower. For safe emails, an increase in precision comes at the expense of recall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d071923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7562076749435666"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "model_LR_scaled = LogisticRegression(class_weight = 'balanced')\n",
    "model_LR_scaled.fit(X_train_scaled,y_train)\n",
    "y_pred = model_LR_scaled.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92415312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "Phishing Email       0.71      0.67      0.69      1429\n",
      "    Safe Email       0.78      0.82      0.80      2115\n",
      "\n",
      "      accuracy                           0.76      3544\n",
      "     macro avg       0.75      0.74      0.74      3544\n",
      "  weighted avg       0.75      0.76      0.75      3544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test,y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f9133e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7631231244686902"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(model_LR_scaled, X_train_scaled, y_train, cv=kf, scoring='accuracy')\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4128613",
   "metadata": {},
   "source": [
    "Some improvement with standardization. Both testing and cross validation accuracy numbers are in the mid 70s. Precision increases for both phishing emails and safe emails at the cost of recall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b5976b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7466139954853274"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "X_test_norm = scaler.transform(X_test)\n",
    "model_LR_norm = LogisticRegression(class_weight='balanced')\n",
    "model_LR_norm.fit(X_train_norm,y_train)\n",
    "y_pred = model_LR_norm.predict(X_test_norm)\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec360725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "Phishing Email       0.69      0.67      0.68      1429\n",
      "    Safe Email       0.78      0.80      0.79      2115\n",
      "\n",
      "      accuracy                           0.75      3544\n",
      "     macro avg       0.74      0.73      0.74      3544\n",
      "  weighted avg       0.75      0.75      0.75      3544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test,y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a3513e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7545152027720835"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(model_LR_norm, X_train_norm, y_train, cv=kf, scoring='accuracy')\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2324bf4-656a-4f08-ab8f-9aadcc825911",
   "metadata": {},
   "source": [
    " The accuracy score for the test and cross validation sets is not substantially better. Precision and recall scores are  almost the same, albeit slightly lower.  Seems like standardization and normalization makes just a slight improvement at best compared to the pre-scaled or pre-normalized model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49b9e4e-b5f4-4e5d-b6d8-b67ad6275ed5",
   "metadata": {},
   "source": [
    "Now do GridSearch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba773f13-6e7e-4c71-83f2-bdedfc13997e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best parameters: {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best cross-validation score: 0.7669\n",
      "Test set accuracy with best model: 0.7573\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Phishing Email       0.72      0.66      0.69      1429\n",
      "    Safe Email       0.78      0.83      0.80      2115\n",
      "\n",
      "      accuracy                           0.76      3544\n",
      "     macro avg       0.75      0.74      0.74      3544\n",
      "  weighted avg       0.76      0.76      0.76      3544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "logistic_regression = LogisticRegression(class_weight='balanced')\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10,100],  # Inverse of regularization strength\n",
    "    'penalty': ['l1', 'l2'],            # Regularization type (L1 or L2)\n",
    "    'solver': ['liblinear', 'saga']     # Solvers that support both L1 and L2\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=logistic_regression,\n",
    "                           param_grid=param_grid,\n",
    "                           cv=5,\n",
    "                           scoring='accuracy',\n",
    "                           verbose=1,\n",
    "                           n_jobs=-1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
    "best_model = grid_search.best_estimator_\n",
    "test_accuracy = best_model.score(X_test_scaled, y_test)\n",
    "print(f\"Test set accuracy with best model: {test_accuracy:.4f}\")\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "report = classification_report(y_test,y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b406e21c-edf1-48a5-b695-a7035179ebca",
   "metadata": {},
   "source": [
    "Slight improvement with GridSearch for cross validation and test accuracy. The precision and recall scores for phishing and safe emails are very similar to those of the standardized Logistic Regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9d206d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_length</th>\n",
       "      <th>n_dots</th>\n",
       "      <th>n_hypens</th>\n",
       "      <th>n_underline</th>\n",
       "      <th>n_slash</th>\n",
       "      <th>n_questionmark</th>\n",
       "      <th>n_equal</th>\n",
       "      <th>n_at</th>\n",
       "      <th>n_and</th>\n",
       "      <th>n_exclamation</th>\n",
       "      <th>n_space</th>\n",
       "      <th>n_tilde</th>\n",
       "      <th>n_comma</th>\n",
       "      <th>n_plus</th>\n",
       "      <th>n_asterisk</th>\n",
       "      <th>n_hastag</th>\n",
       "      <th>n_dollar</th>\n",
       "      <th>n_percent</th>\n",
       "      <th>n_redirection</th>\n",
       "      <th>phishing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100072</th>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100073</th>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100074</th>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100075</th>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100076</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100077 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        url_length  n_dots  n_hypens  n_underline  n_slash  n_questionmark  \\\n",
       "0               37       3         0            0        0               0   \n",
       "1               77       1         0            0        0               0   \n",
       "2              126       4         1            2        0               1   \n",
       "3               18       2         0            0        0               0   \n",
       "4               55       2         2            0        0               0   \n",
       "...            ...     ...       ...          ...      ...             ...   \n",
       "100072          23       3         1            0        0               0   \n",
       "100073          34       2         0            0        0               0   \n",
       "100074          70       2         1            0        5               0   \n",
       "100075          28       2         0            0        1               0   \n",
       "100076          16       2         0            0        0               0   \n",
       "\n",
       "        n_equal  n_at  n_and  n_exclamation  n_space  n_tilde  n_comma  \\\n",
       "0             0     0      0              0        0        0        0   \n",
       "1             0     0      0              0        0        0        0   \n",
       "2             3     0      2              0        0        0        0   \n",
       "3             0     0      0              0        0        0        0   \n",
       "4             0     0      0              0        0        0        0   \n",
       "...         ...   ...    ...            ...      ...      ...      ...   \n",
       "100072        0     0      0              0        0        0        0   \n",
       "100073        0     0      0              0        0        0        0   \n",
       "100074        0     0      0              0        0        0        0   \n",
       "100075        0     0      0              0        0        0        0   \n",
       "100076        0     0      0              0        0        0        0   \n",
       "\n",
       "        n_plus  n_asterisk  n_hastag  n_dollar  n_percent  n_redirection  \\\n",
       "0            0           0         0         0          0              0   \n",
       "1            0           0         0         0          0              1   \n",
       "2            0           0         0         0          0              1   \n",
       "3            0           0         0         0          0              1   \n",
       "4            0           0         0         0          0              1   \n",
       "...        ...         ...       ...       ...        ...            ...   \n",
       "100072       0           0         0         0          0              0   \n",
       "100073       0           0         0         0          0              2   \n",
       "100074       0           0         0         0          0              0   \n",
       "100075       0           0         0         0          0              0   \n",
       "100076       0           0         0         0          0              0   \n",
       "\n",
       "        phishing  \n",
       "0              0  \n",
       "1              1  \n",
       "2              1  \n",
       "3              0  \n",
       "4              0  \n",
       "...          ...  \n",
       "100072         0  \n",
       "100073         0  \n",
       "100074         1  \n",
       "100075         1  \n",
       "100076         0  \n",
       "\n",
       "[100077 rows x 20 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Website = pd.read_csv(\"C:\\\\Users\\\\alfre_g2qn6y7\\\\OneDrive\\\\Documents\\\\web-page-phishing.csv\")\n",
    "Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c022caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8461730615507594"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = Website.drop([\"url_length\",\"phishing\"],axis =1)\n",
    "y = Website[\"phishing\"]\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "model_LR_pre_scaling = LogisticRegression()\n",
    "model_LR_pre_scaling.fit(X_train,y_train)\n",
    "y_pred = model_LR_pre_scaling.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "76ddcab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88     12698\n",
      "           1       0.85      0.70      0.77      7318\n",
      "\n",
      "    accuracy                           0.85     20016\n",
      "   macro avg       0.85      0.82      0.83     20016\n",
      "weighted avg       0.85      0.85      0.84     20016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test,y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4dd86140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8457987749196096"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(model_LR_pre_scaling, X, y, cv=kf, scoring='accuracy')\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703bb6c9",
   "metadata": {},
   "source": [
    "Testing and cross validation accuracy is okay. It is in the 80 percent range. The recall score for phishing (1) is relatively low on average. Let's see what happens when we apply class balance.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c1a4ab11-9761-4e2c-826c-1fe07e33a22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8497202238209433"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LR_pre_scaling = LogisticRegression(class_weight='balanced')\n",
    "model_LR_pre_scaling.fit(X_train,y_train)\n",
    "y_pred = model_LR_pre_scaling.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8e63b6a-b1ad-4f2c-8cfa-48aa49e3788a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89     12698\n",
      "           1       0.85      0.72      0.78      7318\n",
      "\n",
      "    accuracy                           0.85     20016\n",
      "   macro avg       0.85      0.82      0.83     20016\n",
      "weighted avg       0.85      0.85      0.85     20016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test,y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c0987a55-f8e3-4d9b-8d92-ce630047bdb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8490062988330296"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(model_LR_pre_scaling, X, y, cv=kf, scoring='accuracy')\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e334677-9cc0-42c8-860e-dc422d3d7a89",
   "metadata": {},
   "source": [
    "Class balancing results in very little improvement overall for cross validation, test accuracy, precision, and recall scores. But it will be implemented going forward because of the slight improvement that happened. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "18a4f437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8497202238209433"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "model_LR_scaled = LogisticRegression(class_weight='balanced')\n",
    "model_LR_scaled.fit(X_train_scaled,y_train)\n",
    "y_pred = model_LR_scaled.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c711fe62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89     12698\n",
      "           1       0.85      0.72      0.78      7318\n",
      "\n",
      "    accuracy                           0.85     20016\n",
      "   macro avg       0.85      0.82      0.83     20016\n",
      "weighted avg       0.85      0.85      0.85     20016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test,y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "04dc2e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8481907475906528"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(model_LR_scaled, X_train_scaled, y_train, cv=kf, scoring='accuracy')\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5625d521",
   "metadata": {},
   "source": [
    "No significant improvement with standardization.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "91dd98d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.847072342126299"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "X_test_norm = scaler.transform(X_test)\n",
    "model_LR_norm = LogisticRegression(class_weight='balanced')\n",
    "model_LR_norm.fit(X_train_norm,y_train)\n",
    "y_pred = model_LR_norm.predict(X_test_norm)\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "83c0354d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88     12698\n",
      "           1       0.84      0.72      0.77      7318\n",
      "\n",
      "    accuracy                           0.85     20016\n",
      "   macro avg       0.85      0.82      0.83     20016\n",
      "weighted avg       0.85      0.85      0.84     20016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test,y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "320b562a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8481907475906528"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(model_LR_scaled, X_train_scaled, y_train, cv=kf, scoring='accuracy')\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5def662c",
   "metadata": {},
   "source": [
    "No substantial improvement with normalization either. This could be due to an imbalance between the phishing and non-phishing classes (latter outnumber the former) that the class weight paramter doesn't fully address. Now do GridSearchCV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bf009cf4-8e09-49d8-9542-7a59f3946055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best parameters: {'C': 100, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Best cross-validation score: 0.8484\n",
      "Test set accuracy with best model: 0.8496\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89     12698\n",
      "           1       0.85      0.72      0.78      7318\n",
      "\n",
      "    accuracy                           0.85     20016\n",
      "   macro avg       0.85      0.82      0.83     20016\n",
      "weighted avg       0.85      0.85      0.85     20016\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alfre_g2qn6y7\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "logistic_regression = LogisticRegression(class_weight='balanced')\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10,100],  # Inverse of regularization strength\n",
    "    'penalty': ['l1', 'l2'],            # Regularization type (L1 or L2)\n",
    "    'solver': ['liblinear', 'saga']     # Solvers that support both L1 and L2\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=logistic_regression,\n",
    "                           param_grid=param_grid,\n",
    "                           cv=5,\n",
    "                           scoring='accuracy',\n",
    "                           verbose=1,\n",
    "                           n_jobs=-1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
    "best_model = grid_search.best_estimator_\n",
    "test_accuracy = best_model.score(X_test_scaled, y_test)\n",
    "print(f\"Test set accuracy with best model: {test_accuracy:.4f}\")\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "report = classification_report(y_test,y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22947c23-cbff-4339-ae79-cfbd1af15ef3",
   "metadata": {},
   "source": [
    "There is a little improvement in cross-validation score but a slight decrease in test accuracy score. Precision and recall scores are pretty much identical. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
